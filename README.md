# Customerâ€¯Churnâ€¯ModelÂ ğŸ“‰ğŸ›«

A lightweight, endâ€‘toâ€‘end demonstration of predicting customerâ€‘churn risk with classical machineâ€‘learning techniques.  
The current notebook trains a **Randomâ€¯Forest** classifier on the popular *Telco Customer Churn* data set and reports accuracy and a full classification report.:contentReference[oaicite:0]{index=0}

---

## TableÂ ofÂ Contents
1. [ProjectÂ Motivation](#project-motivation)  
2. [Dataset](#dataset)  
3. [Approach & NotebookÂ Walkâ€‘through](#approach--notebook-walk%E2%80%91through)  
4. [QuickÂ Start](#quick-start)  
5. [ProjectÂ Structure](#project-structure)  
6. [Results](#results)    

---

## ProjectÂ Motivation

Churn directly affects a companyâ€™s bottom line: retaining a customer is usually cheaper than acquiring a new one.  
By identifying *who* is at risk *before* they leave, businesses can target retention campaigns more efficiently.  

This repository is meant to be:
- **Educational** â€“ a clear, minimal example of the MLâ€‘forâ€‘churn workflow.  
- **Extendable** â€“ drop in new features, models or MLOps tooling without major refactor.  
- **Reproducible** â€“ a single JupyterÂ Notebook drives the whole pipeline.

---

## Dataset

| Name | Records | Features | Source |
|------|---------|----------|--------|
| TelcoÂ CustomerÂ Churn | 17â€¯000â€¯+ | Demographic, engagement & financial metrics | Automatically downloaded via the `skillsnetwork` helper (IBM SkillsÂ Network).:contentReference[oaicite:1]{index=1} |

*Target*: **`CHURNRISK`** (categorical: *Low*, *Medium*, *High*).

---

## ApproachÂ &Â NotebookÂ Walkâ€‘through

| Step | Description |
|------|-------------|
| **1.â€¯Exploration** | Quick pandas profiling, missingâ€‘value audit, churn distribution. |
| **2.â€¯Preâ€‘processing** | *Numerical*: imputeÂ â†’Â standardâ€‘scale.Â Â *Categorical*: imputeÂ â†’Â Oneâ€‘Hot encode. |
| **3.â€¯Train/Testâ€¯Split** | 80â€¯/â€¯20 with stratification to preserve class balance. |
| **4.â€¯Modelling** | `RandomForestClassifier(n_estimatorsâ€¯=â€¯100, random_stateâ€¯=â€¯42)`. |
| **5.â€¯Evaluation** | Accuracy plus precision/recall/F1 per class; featureâ€‘importance bar chart. |
| **6.â€¯Persistence** | Save the trained RF model with `joblib` (placeholder â€“ uncomment in notebook). |
| **7.â€¯Predictionâ€¯Demo** | Simulate scoring a single customer record. |

> **Why RandomÂ Forest?**  
> Good baseline, handles mixed data types outâ€‘ofâ€‘theâ€‘box, interpretable via feature importance.

---

## QuickÂ Start

 **Clone** the repo  
```
   git clone https://github.com/ShivamMitra/Customer-churn-model.git
   cd Customer-churn-model
```


ProjectÂ Structure
```
Customer-churn-model/
â”‚
â”œâ”€â”€ Churn Probability (Random Forest ) Model.ipynb   â† main notebook
â”œâ”€â”€ requirements.txt                                 â† dependency pinâ€‘list (add yours)
â””â”€â”€ README.md                                        â† you are here
```


Results
```
Metric	Value*
Overallâ€¯Accuracy	~â€¯88â€¯% (demo run, will vary)
MacroÂ F1â€‘Score	~â€¯0.86
Topâ€¯5â€¯Features	TOTALDOLLARVALUETRADED, ESTINCOME, TOTALUNITSTRADED, DAYSSINCELASTLOGIN, NETREALIZEDGAINS_YTD
```
*â€¯See the final notebook cell for the exact run in your environment.
   
